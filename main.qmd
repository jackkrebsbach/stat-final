---
title: "Kaggle Competitions"
author: "Peter Burke, Jack Krebsbach, Ryan Theurer"
date: "`r Sys.Date()`"
format: pdf
editor: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(8675309)
library(pROC)
library(splines)
library(gam)
library(e1071)
library(plotly)
library(tidyverse)
library(leaps)
library(boot)
library(tidymodels)
library(pander)
library(GGally)
library(caret)
library(ggfortify)
library(class)
library(MASS)
library(xgboost)
library(caret)
library(ISLR2)
library(glmnet)
library(pls)
library(ggplot2)
library(gridExtra)
library(dplyr)
'%!in%' <- function(x, y){!('%in%'(x, y))}
```


```{r}
set.seed(86785309)
data <- read.csv("data/train.csv")
initial_split <- initial_split(data)
train <- training(initial_split)
train$Y <- as.factor(train$Y)

test <- testing(initial_split)
test$Y <- as.factor(test$Y)
```

```{r}
t(t(names(train)))
```


```{r}
numeric_featuress <- train %>%
  dplyr::select(is.numeric) %>%
  slice_sample(n = 100)
pairs(numeric_featuress)
```
```{r}
task <- makeClassifTask(data = train, target = "Y", positive = "1")
task_smote <- mlr::smote(task, rate = 2)
learner <- makeLearner("classif.xgboost",
                       predict.type = "prob",
                       nrounds = 200,           
                       max_depth = 8,           
                       eta = 0.1,               
                       colsample_bytree = 0.9,  
                       objective = "binary:logistic")

model <- mlr::train(learner, task_smote)
predictions <- predict(model, newdata = test)
```

```{r}
preds <- setThreshold(predictions, 0.45)
cm_pos <- confusionMatrix(as.factor(test$Y), preds$data$response, positive = "1")
f1_pos <- cm_pos$byClass["F1"]
cat("F1 for class 1:", f1_pos, "\n")
```


